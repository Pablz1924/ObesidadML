# -*- coding: utf-8 -*-
"""Perceptron_obesidad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KxeNK2keI1Sha5x-m_FdNYGVNQkpQMr5

# **Red Neuronal Artificial: PERCEPTRÓN**
```
Autor     : Pabel Sebastian Peña Tejada
Problema  : Obesidad.
```

# **1. IMPORTACIÓN DE LIBRERÍAS**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
import math

from sklearn import metrics
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

"""# **2. IMPORTACIÓN DE DATOS**"""

datos = pd.read_csv("ObesityDataSet_raw_and_data_sinthetic.csv", sep=',')
datos.head()

"""# **3. PREPARACIÓN DE DATOS**

# Determinar si existen datos faltantes
"""

# visualizar información del dataset
datos.info()

#número de valores nulos por cada atributo
datos.isnull().sum()

# Visualizar datos imputados utilizando la media
datos.head()

"""# Conversión de datos Categóricos a Numéricos"""

# Implementación de un módulo que convierte un atributo categórico a numérico
def Categorico_a_numerico(atributo):
    # Convertir el atributo al tipo categórico
    atributo = atributo.astype("category")
    # Convertir el atributo categórico a numérico
    return atributo.astype("category").cat.codes

# convertir los categóricos a numéricos
# datos['EJEMPLO'] = Categorico_a_numerico(datos['EJEMPLO'])
datos['Gender']=Categorico_a_numerico(datos['Gender'])
datos['family_history_with_overweight']=Categorico_a_numerico(datos['family_history_with_overweight'])
datos['FAVC']=Categorico_a_numerico(datos['FAVC'])
datos['CAEC']=Categorico_a_numerico(datos['CAEC'])
datos['SMOKE']=Categorico_a_numerico(datos['SMOKE'])
datos['SCC']=Categorico_a_numerico(datos['SCC'])
datos['CALC']=Categorico_a_numerico(datos['CALC'])
datos['MTRANS']=Categorico_a_numerico(datos['MTRANS'])
datos['NObeyesdad']=Categorico_a_numerico(datos['NObeyesdad'])
# En este caso, no se tiene ningún datos categórico
datos.head()

"""# Implementar la normalización de datos por amplitud"""

# Transformación por amplitud [0..1]
def Normalizacion_Amplitud(atributo):
    return (atributo - atributo.min())/(atributo.max() - atributo.min())

# Datos antes de la normalizacion por amplitud
datos.head()

datos.columns

datos['Gender'] = Normalizacion_Amplitud(datos['Gender'])
datos['Age'] = Normalizacion_Amplitud(datos['Age'])
datos['Height'] = Normalizacion_Amplitud(datos['Height'])
datos['Weight'] = Normalizacion_Amplitud(datos['Weight'])
datos['family_history_with_overweight'] = Normalizacion_Amplitud(datos['family_history_with_overweight'])
datos['FAVC'] = Normalizacion_Amplitud(datos['FAVC'])
datos['FCVC'] = Normalizacion_Amplitud(datos['FCVC'])
datos['NCP'] = Normalizacion_Amplitud(datos['NCP'])
datos['CAEC'] = Normalizacion_Amplitud(datos['CAEC'])
datos['SMOKE'] = Normalizacion_Amplitud(datos['SMOKE'])
datos['CH2O'] = Normalizacion_Amplitud(datos['CH2O'])
datos['SCC'] = Normalizacion_Amplitud(datos['SCC'])
datos['FAF'] = Normalizacion_Amplitud(datos['FAF'])
datos['TUE'] = Normalizacion_Amplitud(datos['TUE'])
datos['CALC'] = Normalizacion_Amplitud(datos['CALC'])
datos['MTRANS'] = Normalizacion_Amplitud(datos['MTRANS'])

# Datos después de la normalizacion por amplitud
datos.head()

datos.shape

"""# **4. SEPARADO DE DATOS**"""

X = datos.drop('NObeyesdad', axis=1)  # Características
y = datos['NObeyesdad']  # Variable objetivo

# División de los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

"""# **5. CONFIGURACIÓN DEL MODELO**"""

modelo = MLPClassifier(hidden_layer_sizes = (100, 50),activation = 'relu',solver = 'adam'  ,alpha = 0.0001  ,max_iter = 200  ,learning_rate = 'constant')

"""# **6. ENTRENAR MODELO**"""

modelo.fit(X_train, y_train)

"""# **7. TEST**"""

y_pred = modelo.predict(X_test)

"""# **8. MATRIZ CONJUGADA**"""

matriz_confusion = metrics.confusion_matrix(y_test, y_pred)
print('matriz de confusión\n', matriz_confusion)

"""# **9. OBTENER MÉTRICAS**"""

accuracy = metrics.accuracy_score(y_test, y_pred)
precision = metrics.precision_score(y_test, y_pred, average='weighted')
recall = metrics.recall_score(y_test, y_pred, average='weighted')
f1_score = metrics.f1_score(y_test, y_pred, average='weighted')

print("Accuracy: ", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("f1", f1_score)

"""# **10. NUEVAS PREDICCIONES**"""

import warnings

# Desactivar advertencias
warnings.filterwarnings("ignore", category=UserWarning)

nuevos_datos = [[1.0, 0.275, 0.400, 0.250, 0.0, 1.0, 0.6, 0.4, 0.2, 0.0, 0.8, 0.0, 0.25, 0.75, 0.5, 0.5]]

predicciones_nuevas = modelo.predict(nuevos_datos)
print(predicciones_nuevas)

from google.colab import files
uploaded = files.upload()

!jupyter nbconvert --to script Perceptron_obesidad.ipynb